{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we start including all the necessary packages for creating our neural network\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 10:44:40.963593: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-23 10:44:40.968123: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-23 10:44:41.054346: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-23 10:44:41.056311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 10:44:43.041127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Genetic_Marker_1   1000 non-null   float64\n",
      " 1   Genetic_Marker_2   1000 non-null   float64\n",
      " 2   Genetic_Marker_3   1000 non-null   float64\n",
      " 3   Genetic_Marker_4   1000 non-null   float64\n",
      " 4   Genetic_Marker_5   1000 non-null   float64\n",
      " 5   Gene_Expression_1  1000 non-null   float64\n",
      " 6   Gene_Expression_2  1000 non-null   float64\n",
      " 7   Gene_Expression_3  1000 non-null   float64\n",
      " 8   Gene_Expression_4  1000 non-null   float64\n",
      " 9   Gene_Expression_5  1000 non-null   float64\n",
      " 10  Obesity_Risk       1000 non-null   int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 86.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genetic_Marker_1</th>\n",
       "      <th>Genetic_Marker_2</th>\n",
       "      <th>Genetic_Marker_3</th>\n",
       "      <th>Genetic_Marker_4</th>\n",
       "      <th>Genetic_Marker_5</th>\n",
       "      <th>Gene_Expression_1</th>\n",
       "      <th>Gene_Expression_2</th>\n",
       "      <th>Gene_Expression_3</th>\n",
       "      <th>Gene_Expression_4</th>\n",
       "      <th>Gene_Expression_5</th>\n",
       "      <th>Obesity_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.045257</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>-0.051229</td>\n",
       "      <td>-0.018943</td>\n",
       "      <td>0.028181</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>-0.030679</td>\n",
       "      <td>-0.051803</td>\n",
       "      <td>-0.024486</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.987527</td>\n",
       "      <td>0.968644</td>\n",
       "      <td>0.954594</td>\n",
       "      <td>1.016321</td>\n",
       "      <td>0.998364</td>\n",
       "      <td>0.984075</td>\n",
       "      <td>1.010006</td>\n",
       "      <td>0.977247</td>\n",
       "      <td>0.966445</td>\n",
       "      <td>1.011478</td>\n",
       "      <td>0.500241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.046143</td>\n",
       "      <td>-2.994613</td>\n",
       "      <td>-3.116857</td>\n",
       "      <td>-3.740101</td>\n",
       "      <td>-3.007437</td>\n",
       "      <td>-2.758928</td>\n",
       "      <td>-3.069207</td>\n",
       "      <td>-3.126201</td>\n",
       "      <td>-3.017878</td>\n",
       "      <td>-2.924153</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.698420</td>\n",
       "      <td>-0.653850</td>\n",
       "      <td>-0.736665</td>\n",
       "      <td>-0.710473</td>\n",
       "      <td>-0.626991</td>\n",
       "      <td>-0.674275</td>\n",
       "      <td>-0.686790</td>\n",
       "      <td>-0.655465</td>\n",
       "      <td>-0.691064</td>\n",
       "      <td>-0.735930</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.058028</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>-0.052498</td>\n",
       "      <td>-0.028266</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.037867</td>\n",
       "      <td>-0.048544</td>\n",
       "      <td>-0.036704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.606951</td>\n",
       "      <td>0.625480</td>\n",
       "      <td>0.621616</td>\n",
       "      <td>0.661825</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.630594</td>\n",
       "      <td>0.718528</td>\n",
       "      <td>0.589043</td>\n",
       "      <td>0.583051</td>\n",
       "      <td>0.682870</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.759355</td>\n",
       "      <td>3.170975</td>\n",
       "      <td>2.929096</td>\n",
       "      <td>3.801660</td>\n",
       "      <td>2.979976</td>\n",
       "      <td>2.841767</td>\n",
       "      <td>2.956399</td>\n",
       "      <td>3.292694</td>\n",
       "      <td>3.019670</td>\n",
       "      <td>2.865204</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genetic_Marker_1  Genetic_Marker_2  Genetic_Marker_3  Genetic_Marker_4  \\\n",
       "count       1000.000000       1000.000000       1000.000000       1000.000000   \n",
       "mean          -0.045257          0.013617         -0.051229         -0.018943   \n",
       "std            0.987527          0.968644          0.954594          1.016321   \n",
       "min           -3.046143         -2.994613         -3.116857         -3.740101   \n",
       "25%           -0.698420         -0.653850         -0.736665         -0.710473   \n",
       "50%           -0.058028          0.026062         -0.052498         -0.028266   \n",
       "75%            0.606951          0.625480          0.621616          0.661825   \n",
       "max            2.759355          3.170975          2.929096          3.801660   \n",
       "\n",
       "       Genetic_Marker_5  Gene_Expression_1  Gene_Expression_2  \\\n",
       "count       1000.000000        1000.000000        1000.000000   \n",
       "mean           0.028181          -0.019053           0.015315   \n",
       "std            0.998364           0.984075           1.010006   \n",
       "min           -3.007437          -2.758928          -3.069207   \n",
       "25%           -0.626991          -0.674275          -0.686790   \n",
       "50%            0.025696          -0.014536          -0.003791   \n",
       "75%            0.713642           0.630594           0.718528   \n",
       "max            2.979976           2.841767           2.956399   \n",
       "\n",
       "       Gene_Expression_3  Gene_Expression_4  Gene_Expression_5  Obesity_Risk  \n",
       "count        1000.000000        1000.000000        1000.000000   1000.000000  \n",
       "mean           -0.030679          -0.051803          -0.024486      0.497000  \n",
       "std             0.977247           0.966445           1.011478      0.500241  \n",
       "min            -3.126201          -3.017878          -2.924153      0.000000  \n",
       "25%            -0.655465          -0.691064          -0.735930      0.000000  \n",
       "50%            -0.037867          -0.048544          -0.036704      0.000000  \n",
       "75%             0.589043           0.583051           0.682870      1.000000  \n",
       "max             3.292694           3.019670           2.865204      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. We read the document\n",
    "\n",
    "df = pd.read_excel('Data set 3_obesity_risk_prediction_dataset.xlsx')\n",
    "\n",
    "# 2. We explore the dataframa to know its structure\n",
    "\n",
    "df\n",
    "df.columns\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. We standarize the dataframe\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. And now we split the dataset into training and test sets.\n",
    "y = df.iloc[:, -1] # Our target variable is the obesity risk, which is the last column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of the FFNN\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 9, activation = 'relu',\n",
    "                     kernel_initializer='glorot_uniform', input_dim = 10)) # The target variable is predicted using 10 inputs\n",
    "classifier.add(Dense(units = 3, activation = 'relu')) # And we add two hidden layers (one with 4 neurons and another one with 3 neurons)\n",
    "classifier.add(Dense(units = 4, activation = 'relu'))\n",
    "\n",
    "# The last layer is the output layer, which uses one neuron and the sigmoid activation function since we are just doing a binary classification\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compile our FFNN using the adam optimizer and the binary:crossentropy as the loss function\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 2s 4ms/step - loss: 0.6955 - accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5300\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5288\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5325\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5250\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5288\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5362\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5350\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5350\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa2fc743130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we train our FFNN using batch training\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 20, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Now we have to evaluate our model. We are going to use our FFNN to predict target variables\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred = round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.52      0.62       147\n",
      "         1.0       0.29      0.55      0.38        53\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.53      0.53      0.50       200\n",
      "weighted avg       0.64      0.53      0.55       200\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The parameters we are asked for (accuracy, precision, recall, and F1-score) are obtained through the classification report)\n",
    "\n",
    "cr = classification_report(y_pred, y_test)\n",
    "print('Classification Report :\\n', cr) # it is used to measure the quality of predictions from a classification algorithm\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[76 24]\n",
      " [71 29]]\n"
     ]
    }
   ],
   "source": [
    "# We are also going to evaluate our model with the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix :\\n', cm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
